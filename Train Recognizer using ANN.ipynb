{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Recognizer Model using ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the face embeddings\n",
    "data=pickle.loads(open(r\"C:\\Users\\SRKT\\Desktop\\opencv-face-recognition\\output\\Train\\embeddings.pickle\",\"rb\").read())\n",
    "\n",
    "emb=np.array(data[\"embedding\"])\n",
    "labelt=np.array(data[\"names\"])\n",
    "#encode the labels\n",
    "le=LabelEncoder()\n",
    "labels=le.fit_transform(labelt)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train,x_test,y_train,y_test)=train_test_split(data[\"embedding\"],labels,test_size=0.2,stratify=labels,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT=pickle.loads(open(r\"C:\\Users\\SRKT\\Desktop\\opencv-face-recognition\\output\\Test\\embeddings.pickle\",\"rb\").read())\n",
    "\n",
    "embT=np.array(dataT[\"embedding\"])\n",
    "labelT=np.array(dataT[\"names\"])\n",
    "#encode the labels\n",
    "ler=LabelEncoder()\n",
    "labelsT=ler.fit_transform(labelT)\n",
    "len(labelsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(512,input_shape=(128,),kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,kernel_initializer=\"he_normal\",bias_initializer=\"zeros\",activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(len(le.classes_),activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt=SGD(lr=1e-4,momentum=0.9,decay=1e-4/50)\n",
    "#opt=RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
    "opt=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 247 samples\n",
      "Epoch 1/450\n",
      "716/716 [==============================] - 3s 4ms/sample - loss: 1.8583 - accuracy: 0.1885 - val_loss: 1.5940 - val_accuracy: 0.2470\n",
      "Epoch 2/450\n",
      "716/716 [==============================] - 0s 698us/sample - loss: 1.7680 - accuracy: 0.1997 - val_loss: 1.5845 - val_accuracy: 0.3036\n",
      "Epoch 3/450\n",
      "716/716 [==============================] - 1s 716us/sample - loss: 1.7593 - accuracy: 0.2151 - val_loss: 1.5759 - val_accuracy: 0.3522\n",
      "Epoch 4/450\n",
      "716/716 [==============================] - 0s 688us/sample - loss: 1.7440 - accuracy: 0.1927 - val_loss: 1.5693 - val_accuracy: 0.3725\n",
      "Epoch 5/450\n",
      "716/716 [==============================] - 0s 696us/sample - loss: 1.6617 - accuracy: 0.2137 - val_loss: 1.5649 - val_accuracy: 0.4008\n",
      "Epoch 6/450\n",
      "716/716 [==============================] - 1s 723us/sample - loss: 1.6881 - accuracy: 0.2095 - val_loss: 1.5614 - val_accuracy: 0.4413\n",
      "Epoch 7/450\n",
      "716/716 [==============================] - 1s 702us/sample - loss: 1.6825 - accuracy: 0.2081 - val_loss: 1.5577 - val_accuracy: 0.4575\n",
      "Epoch 8/450\n",
      "716/716 [==============================] - 1s 918us/sample - loss: 1.6639 - accuracy: 0.2249 - val_loss: 1.5487 - val_accuracy: 0.4453\n",
      "Epoch 9/450\n",
      "716/716 [==============================] - 1s 976us/sample - loss: 1.6043 - accuracy: 0.2528 - val_loss: 1.5373 - val_accuracy: 0.4170\n",
      "Epoch 10/450\n",
      "716/716 [==============================] - 1s 930us/sample - loss: 1.6012 - accuracy: 0.2626 - val_loss: 1.5217 - val_accuracy: 0.4291\n",
      "Epoch 11/450\n",
      "716/716 [==============================] - 1s 917us/sample - loss: 1.5983 - accuracy: 0.2542 - val_loss: 1.5097 - val_accuracy: 0.4332\n",
      "Epoch 12/450\n",
      "716/716 [==============================] - 1s 865us/sample - loss: 1.5639 - accuracy: 0.2598 - val_loss: 1.4909 - val_accuracy: 0.4008\n",
      "Epoch 13/450\n",
      "716/716 [==============================] - 1s 896us/sample - loss: 1.5748 - accuracy: 0.2668 - val_loss: 1.4630 - val_accuracy: 0.3927\n",
      "Epoch 14/450\n",
      "716/716 [==============================] - 1s 889us/sample - loss: 1.5562 - accuracy: 0.2989 - val_loss: 1.4306 - val_accuracy: 0.4130\n",
      "Epoch 15/450\n",
      "716/716 [==============================] - 1s 880us/sample - loss: 1.5077 - accuracy: 0.3017 - val_loss: 1.3943 - val_accuracy: 0.4413\n",
      "Epoch 16/450\n",
      "716/716 [==============================] - 1s 891us/sample - loss: 1.4491 - accuracy: 0.3338 - val_loss: 1.3633 - val_accuracy: 0.4332\n",
      "Epoch 17/450\n",
      "716/716 [==============================] - 1s 890us/sample - loss: 1.4391 - accuracy: 0.3520 - val_loss: 1.3426 - val_accuracy: 0.4211\n",
      "Epoch 18/450\n",
      "716/716 [==============================] - 1s 893us/sample - loss: 1.4602 - accuracy: 0.3198 - val_loss: 1.3155 - val_accuracy: 0.4291\n",
      "Epoch 19/450\n",
      "716/716 [==============================] - 1s 907us/sample - loss: 1.3871 - accuracy: 0.3785 - val_loss: 1.3109 - val_accuracy: 0.4413\n",
      "Epoch 20/450\n",
      "716/716 [==============================] - 1s 883us/sample - loss: 1.4037 - accuracy: 0.3408 - val_loss: 1.3033 - val_accuracy: 0.4332\n",
      "Epoch 21/450\n",
      "716/716 [==============================] - 1s 901us/sample - loss: 1.3529 - accuracy: 0.3855 - val_loss: 1.2915 - val_accuracy: 0.4332\n",
      "Epoch 22/450\n",
      "716/716 [==============================] - 1s 889us/sample - loss: 1.3624 - accuracy: 0.3827 - val_loss: 1.2824 - val_accuracy: 0.4251\n",
      "Epoch 23/450\n",
      "716/716 [==============================] - 1s 919us/sample - loss: 1.3498 - accuracy: 0.3589 - val_loss: 1.2776 - val_accuracy: 0.4211\n",
      "Epoch 24/450\n",
      "716/716 [==============================] - 1s 896us/sample - loss: 1.3607 - accuracy: 0.3589 - val_loss: 1.2780 - val_accuracy: 0.4049\n",
      "Epoch 25/450\n",
      "716/716 [==============================] - 1s 896us/sample - loss: 1.3656 - accuracy: 0.3534 - val_loss: 1.2718 - val_accuracy: 0.4170\n",
      "Epoch 26/450\n",
      "716/716 [==============================] - 1s 909us/sample - loss: 1.3363 - accuracy: 0.3659 - val_loss: 1.2586 - val_accuracy: 0.4332\n",
      "Epoch 27/450\n",
      "716/716 [==============================] - 1s 715us/sample - loss: 1.3295 - accuracy: 0.3897 - val_loss: 1.2574 - val_accuracy: 0.4534\n",
      "Epoch 28/450\n",
      "716/716 [==============================] - 1s 731us/sample - loss: 1.3031 - accuracy: 0.4176 - val_loss: 1.2417 - val_accuracy: 0.4534\n",
      "Epoch 29/450\n",
      "716/716 [==============================] - 1s 788us/sample - loss: 1.3101 - accuracy: 0.4036 - val_loss: 1.2474 - val_accuracy: 0.4413\n",
      "Epoch 30/450\n",
      "716/716 [==============================] - 1s 893us/sample - loss: 1.3044 - accuracy: 0.3869 - val_loss: 1.2388 - val_accuracy: 0.4453\n",
      "Epoch 31/450\n",
      "716/716 [==============================] - 1s 845us/sample - loss: 1.3232 - accuracy: 0.3701 - val_loss: 1.2428 - val_accuracy: 0.4615\n",
      "Epoch 32/450\n",
      "716/716 [==============================] - 1s 833us/sample - loss: 1.2952 - accuracy: 0.3994 - val_loss: 1.2570 - val_accuracy: 0.4575\n",
      "Epoch 33/450\n",
      "716/716 [==============================] - 1s 837us/sample - loss: 1.2887 - accuracy: 0.4120 - val_loss: 1.2376 - val_accuracy: 0.4656\n",
      "Epoch 34/450\n",
      "716/716 [==============================] - 1s 834us/sample - loss: 1.2852 - accuracy: 0.3966 - val_loss: 1.2395 - val_accuracy: 0.4737\n",
      "Epoch 35/450\n",
      "716/716 [==============================] - 1s 832us/sample - loss: 1.2578 - accuracy: 0.4148 - val_loss: 1.2319 - val_accuracy: 0.4777\n",
      "Epoch 36/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 1.2313 - accuracy: 0.4288 - val_loss: 1.2198 - val_accuracy: 0.4575\n",
      "Epoch 37/450\n",
      "716/716 [==============================] - 1s 843us/sample - loss: 1.2698 - accuracy: 0.4260 - val_loss: 1.2199 - val_accuracy: 0.4696\n",
      "Epoch 38/450\n",
      "716/716 [==============================] - 1s 838us/sample - loss: 1.2595 - accuracy: 0.4176 - val_loss: 1.2139 - val_accuracy: 0.4696\n",
      "Epoch 39/450\n",
      "716/716 [==============================] - 1s 838us/sample - loss: 1.2543 - accuracy: 0.4106 - val_loss: 1.1984 - val_accuracy: 0.4818\n",
      "Epoch 40/450\n",
      "716/716 [==============================] - 1s 836us/sample - loss: 1.2664 - accuracy: 0.4302 - val_loss: 1.1976 - val_accuracy: 0.4656\n",
      "Epoch 41/450\n",
      "716/716 [==============================] - 1s 835us/sample - loss: 1.2702 - accuracy: 0.4260 - val_loss: 1.1905 - val_accuracy: 0.4656\n",
      "Epoch 42/450\n",
      "716/716 [==============================] - 1s 840us/sample - loss: 1.2634 - accuracy: 0.4399 - val_loss: 1.1834 - val_accuracy: 0.4737\n",
      "Epoch 43/450\n",
      "716/716 [==============================] - 1s 833us/sample - loss: 1.2394 - accuracy: 0.4106 - val_loss: 1.1756 - val_accuracy: 0.4777\n",
      "Epoch 44/450\n",
      "716/716 [==============================] - 1s 837us/sample - loss: 1.2219 - accuracy: 0.4441 - val_loss: 1.1654 - val_accuracy: 0.4656\n",
      "Epoch 45/450\n",
      "716/716 [==============================] - 1s 839us/sample - loss: 1.2289 - accuracy: 0.4441 - val_loss: 1.1633 - val_accuracy: 0.4899\n",
      "Epoch 46/450\n",
      "716/716 [==============================] - 1s 836us/sample - loss: 1.2220 - accuracy: 0.4651 - val_loss: 1.1556 - val_accuracy: 0.4656\n",
      "Epoch 47/450\n",
      "716/716 [==============================] - 1s 835us/sample - loss: 1.2252 - accuracy: 0.4497 - val_loss: 1.1430 - val_accuracy: 0.4818\n",
      "Epoch 48/450\n",
      "716/716 [==============================] - 1s 842us/sample - loss: 1.2227 - accuracy: 0.4385 - val_loss: 1.1309 - val_accuracy: 0.4656\n",
      "Epoch 49/450\n",
      "716/716 [==============================] - 1s 839us/sample - loss: 1.1774 - accuracy: 0.4818 - val_loss: 1.1233 - val_accuracy: 0.4696\n",
      "Epoch 50/450\n",
      "716/716 [==============================] - 1s 832us/sample - loss: 1.1937 - accuracy: 0.4665 - val_loss: 1.1188 - val_accuracy: 0.4858\n",
      "Epoch 51/450\n",
      "716/716 [==============================] - 1s 844us/sample - loss: 1.1844 - accuracy: 0.4707 - val_loss: 1.1143 - val_accuracy: 0.4737\n",
      "Epoch 52/450\n",
      "716/716 [==============================] - 1s 841us/sample - loss: 1.1846 - accuracy: 0.4860 - val_loss: 1.1094 - val_accuracy: 0.4939\n",
      "Epoch 53/450\n",
      "716/716 [==============================] - 1s 838us/sample - loss: 1.1834 - accuracy: 0.4832 - val_loss: 1.1041 - val_accuracy: 0.4980\n",
      "Epoch 54/450\n",
      "716/716 [==============================] - 1s 837us/sample - loss: 1.1622 - accuracy: 0.4888 - val_loss: 1.1047 - val_accuracy: 0.4939\n",
      "Epoch 55/450\n",
      "716/716 [==============================] - 1s 834us/sample - loss: 1.1796 - accuracy: 0.4874 - val_loss: 1.0958 - val_accuracy: 0.4939\n",
      "Epoch 56/450\n",
      "716/716 [==============================] - 1s 823us/sample - loss: 1.1474 - accuracy: 0.4763 - val_loss: 1.0954 - val_accuracy: 0.4939\n",
      "Epoch 57/450\n",
      "716/716 [==============================] - 1s 813us/sample - loss: 1.1162 - accuracy: 0.5293 - val_loss: 1.0895 - val_accuracy: 0.4939\n",
      "Epoch 58/450\n",
      "716/716 [==============================] - 1s 818us/sample - loss: 1.1434 - accuracy: 0.4930 - val_loss: 1.0881 - val_accuracy: 0.4939\n",
      "Epoch 59/450\n",
      "716/716 [==============================] - 1s 817us/sample - loss: 1.1534 - accuracy: 0.5028 - val_loss: 1.0848 - val_accuracy: 0.4777\n",
      "Epoch 60/450\n",
      "716/716 [==============================] - 1s 822us/sample - loss: 1.1378 - accuracy: 0.5307 - val_loss: 1.0797 - val_accuracy: 0.5061\n",
      "Epoch 61/450\n",
      "716/716 [==============================] - 1s 812us/sample - loss: 1.1234 - accuracy: 0.5084 - val_loss: 1.0849 - val_accuracy: 0.4939\n",
      "Epoch 62/450\n",
      "716/716 [==============================] - 1s 819us/sample - loss: 1.1544 - accuracy: 0.4777 - val_loss: 1.0708 - val_accuracy: 0.4980\n",
      "Epoch 63/450\n",
      "716/716 [==============================] - 1s 819us/sample - loss: 1.1500 - accuracy: 0.4958 - val_loss: 1.0722 - val_accuracy: 0.5061\n",
      "Epoch 64/450\n",
      "716/716 [==============================] - 1s 817us/sample - loss: 1.1015 - accuracy: 0.5251 - val_loss: 1.0779 - val_accuracy: 0.4737\n",
      "Epoch 65/450\n",
      "716/716 [==============================] - 1s 813us/sample - loss: 1.1256 - accuracy: 0.5209 - val_loss: 1.0698 - val_accuracy: 0.5304\n",
      "Epoch 66/450\n",
      "716/716 [==============================] - 1s 815us/sample - loss: 1.1102 - accuracy: 0.5084 - val_loss: 1.0650 - val_accuracy: 0.4939\n",
      "Epoch 67/450\n",
      "716/716 [==============================] - 1s 822us/sample - loss: 1.1105 - accuracy: 0.5098 - val_loss: 1.0537 - val_accuracy: 0.5142\n",
      "Epoch 68/450\n",
      "716/716 [==============================] - 1s 811us/sample - loss: 1.0852 - accuracy: 0.5182 - val_loss: 1.0493 - val_accuracy: 0.4899\n",
      "Epoch 69/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 1.0907 - accuracy: 0.5363 - val_loss: 1.0499 - val_accuracy: 0.4899\n",
      "Epoch 70/450\n",
      "716/716 [==============================] - 1s 758us/sample - loss: 1.0950 - accuracy: 0.5307 - val_loss: 1.0456 - val_accuracy: 0.5223\n",
      "Epoch 71/450\n",
      "716/716 [==============================] - 1s 750us/sample - loss: 1.1152 - accuracy: 0.5056 - val_loss: 1.0333 - val_accuracy: 0.5304\n",
      "Epoch 72/450\n",
      "716/716 [==============================] - 1s 749us/sample - loss: 1.0667 - accuracy: 0.5335 - val_loss: 1.0370 - val_accuracy: 0.5263\n",
      "Epoch 73/450\n",
      "716/716 [==============================] - 1s 760us/sample - loss: 1.0706 - accuracy: 0.5335 - val_loss: 1.0318 - val_accuracy: 0.5304\n",
      "Epoch 74/450\n",
      "716/716 [==============================] - 1s 753us/sample - loss: 1.0790 - accuracy: 0.5545 - val_loss: 1.0264 - val_accuracy: 0.5385\n",
      "Epoch 75/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 1.0544 - accuracy: 0.5293 - val_loss: 1.0270 - val_accuracy: 0.5466\n",
      "Epoch 76/450\n",
      "716/716 [==============================] - 1s 757us/sample - loss: 1.0307 - accuracy: 0.5712 - val_loss: 1.0250 - val_accuracy: 0.5223\n",
      "Epoch 77/450\n",
      "716/716 [==============================] - 1s 759us/sample - loss: 1.0487 - accuracy: 0.5419 - val_loss: 1.0202 - val_accuracy: 0.5506\n",
      "Epoch 78/450\n",
      "716/716 [==============================] - 1s 762us/sample - loss: 1.0396 - accuracy: 0.5489 - val_loss: 1.0084 - val_accuracy: 0.5466\n",
      "Epoch 79/450\n",
      "716/716 [==============================] - 1s 754us/sample - loss: 1.0485 - accuracy: 0.5461 - val_loss: 1.0002 - val_accuracy: 0.5749\n",
      "Epoch 80/450\n",
      "716/716 [==============================] - 1s 755us/sample - loss: 1.0334 - accuracy: 0.5447 - val_loss: 0.9985 - val_accuracy: 0.5587\n",
      "Epoch 81/450\n",
      "716/716 [==============================] - 1s 763us/sample - loss: 1.0493 - accuracy: 0.5601 - val_loss: 1.0039 - val_accuracy: 0.5506\n",
      "Epoch 82/450\n",
      "716/716 [==============================] - ETA: 0s - loss: 1.0215 - accuracy: 0.58 - 1s 750us/sample - loss: 1.0127 - accuracy: 0.5880 - val_loss: 1.0024 - val_accuracy: 0.5506\n",
      "Epoch 83/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 1.0466 - accuracy: 0.5712 - val_loss: 0.9913 - val_accuracy: 0.5830\n",
      "Epoch 84/450\n",
      "716/716 [==============================] - 1s 757us/sample - loss: 0.9777 - accuracy: 0.5852 - val_loss: 0.9853 - val_accuracy: 0.5789\n",
      "Epoch 85/450\n",
      "716/716 [==============================] - 1s 758us/sample - loss: 0.9950 - accuracy: 0.5628 - val_loss: 0.9885 - val_accuracy: 0.5789\n",
      "Epoch 86/450\n",
      "716/716 [==============================] - 1s 765us/sample - loss: 1.0081 - accuracy: 0.5517 - val_loss: 0.9828 - val_accuracy: 0.5830\n",
      "Epoch 87/450\n",
      "716/716 [==============================] - 1s 762us/sample - loss: 1.0277 - accuracy: 0.5517 - val_loss: 0.9753 - val_accuracy: 0.5951\n",
      "Epoch 88/450\n",
      "716/716 [==============================] - 1s 759us/sample - loss: 0.9589 - accuracy: 0.6103 - val_loss: 0.9733 - val_accuracy: 0.5911\n",
      "Epoch 89/450\n",
      "716/716 [==============================] - 1s 753us/sample - loss: 0.9939 - accuracy: 0.6047 - val_loss: 0.9642 - val_accuracy: 0.5992\n",
      "Epoch 90/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 0.9829 - accuracy: 0.5964 - val_loss: 0.9668 - val_accuracy: 0.6032\n",
      "Epoch 91/450\n",
      "716/716 [==============================] - 0s 655us/sample - loss: 0.9964 - accuracy: 0.5824 - val_loss: 0.9742 - val_accuracy: 0.5911\n",
      "Epoch 92/450\n",
      "716/716 [==============================] - 0s 670us/sample - loss: 0.9812 - accuracy: 0.5908 - val_loss: 0.9651 - val_accuracy: 0.6032\n",
      "Epoch 93/450\n",
      "716/716 [==============================] - 0s 689us/sample - loss: 0.9462 - accuracy: 0.5810 - val_loss: 0.9600 - val_accuracy: 0.6032\n",
      "Epoch 94/450\n",
      "716/716 [==============================] - 0s 678us/sample - loss: 0.9560 - accuracy: 0.5810 - val_loss: 0.9598 - val_accuracy: 0.6073\n",
      "Epoch 95/450\n",
      "716/716 [==============================] - 1s 817us/sample - loss: 0.9286 - accuracy: 0.6313 - val_loss: 0.9590 - val_accuracy: 0.5951\n",
      "Epoch 96/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 0.9412 - accuracy: 0.5866 - val_loss: 0.9556 - val_accuracy: 0.6113\n",
      "Epoch 97/450\n",
      "716/716 [==============================] - 1s 839us/sample - loss: 0.9642 - accuracy: 0.5950 - val_loss: 0.9606 - val_accuracy: 0.5911\n",
      "Epoch 98/450\n",
      "716/716 [==============================] - 1s 758us/sample - loss: 0.9632 - accuracy: 0.6020 - val_loss: 0.9564 - val_accuracy: 0.6032\n",
      "Epoch 99/450\n",
      "716/716 [==============================] - 1s 835us/sample - loss: 0.9354 - accuracy: 0.6285 - val_loss: 0.9603 - val_accuracy: 0.5951\n",
      "Epoch 100/450\n",
      "716/716 [==============================] - 1s 887us/sample - loss: 0.9099 - accuracy: 0.6103 - val_loss: 0.9562 - val_accuracy: 0.6073\n",
      "Epoch 101/450\n",
      "716/716 [==============================] - 1s 797us/sample - loss: 0.9356 - accuracy: 0.6201 - val_loss: 0.9597 - val_accuracy: 0.5951\n",
      "Epoch 102/450\n",
      "716/716 [==============================] - 1s 805us/sample - loss: 0.9443 - accuracy: 0.6229 - val_loss: 0.9622 - val_accuracy: 0.6073\n",
      "Epoch 103/450\n",
      "716/716 [==============================] - 1s 716us/sample - loss: 0.9066 - accuracy: 0.6061 - val_loss: 0.9565 - val_accuracy: 0.5992\n",
      "Epoch 104/450\n",
      "716/716 [==============================] - 1s 893us/sample - loss: 0.9172 - accuracy: 0.6257 - val_loss: 0.9564 - val_accuracy: 0.6032\n",
      "Epoch 105/450\n",
      "716/716 [==============================] - 1s 808us/sample - loss: 0.8986 - accuracy: 0.6508 - val_loss: 0.9536 - val_accuracy: 0.6073\n",
      "Epoch 106/450\n",
      "716/716 [==============================] - 1s 988us/sample - loss: 0.8712 - accuracy: 0.6369 - val_loss: 0.9569 - val_accuracy: 0.5992\n",
      "Epoch 107/450\n",
      "716/716 [==============================] - 1s 941us/sample - loss: 0.9164 - accuracy: 0.6341 - val_loss: 0.9577 - val_accuracy: 0.6073\n",
      "Epoch 108/450\n",
      "716/716 [==============================] - 1s 909us/sample - loss: 0.8824 - accuracy: 0.6285 - val_loss: 0.9598 - val_accuracy: 0.6032\n",
      "Epoch 109/450\n",
      "716/716 [==============================] - 1s 895us/sample - loss: 0.8809 - accuracy: 0.6606 - val_loss: 0.9632 - val_accuracy: 0.6073\n",
      "Epoch 110/450\n",
      "716/716 [==============================] - 1s 954us/sample - loss: 0.8761 - accuracy: 0.6536 - val_loss: 0.9623 - val_accuracy: 0.5870\n",
      "Epoch 111/450\n",
      "716/716 [==============================] - 1s 860us/sample - loss: 0.8445 - accuracy: 0.6564 - val_loss: 0.9656 - val_accuracy: 0.5870\n",
      "Epoch 112/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 0.8457 - accuracy: 0.6634 - val_loss: 0.9616 - val_accuracy: 0.6032\n",
      "Epoch 113/450\n",
      "716/716 [==============================] - 1s 890us/sample - loss: 0.8763 - accuracy: 0.6480 - val_loss: 0.9595 - val_accuracy: 0.5911\n",
      "Epoch 114/450\n",
      "716/716 [==============================] - 1s 782us/sample - loss: 0.8347 - accuracy: 0.6760 - val_loss: 0.9679 - val_accuracy: 0.5911\n",
      "Epoch 115/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 0.8461 - accuracy: 0.6634 - val_loss: 0.9485 - val_accuracy: 0.5992\n",
      "Epoch 116/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.8184 - accuracy: 0.6494 - val_loss: 0.9505 - val_accuracy: 0.5992\n",
      "Epoch 117/450\n",
      "716/716 [==============================] - 1s 943us/sample - loss: 0.7951 - accuracy: 0.6816 - val_loss: 0.9632 - val_accuracy: 0.5951\n",
      "Epoch 118/450\n",
      "716/716 [==============================] - 1s 868us/sample - loss: 0.8586 - accuracy: 0.6732 - val_loss: 0.9702 - val_accuracy: 0.6113\n",
      "Epoch 119/450\n",
      "716/716 [==============================] - 1s 902us/sample - loss: 0.7996 - accuracy: 0.6690 - val_loss: 0.9526 - val_accuracy: 0.5992\n",
      "Epoch 120/450\n",
      "716/716 [==============================] - 1s 917us/sample - loss: 0.8081 - accuracy: 0.6858 - val_loss: 0.9534 - val_accuracy: 0.6073\n",
      "Epoch 121/450\n",
      "716/716 [==============================] - 1s 894us/sample - loss: 0.7859 - accuracy: 0.6885 - val_loss: 0.9483 - val_accuracy: 0.6032\n",
      "Epoch 122/450\n",
      "716/716 [==============================] - 1s 854us/sample - loss: 0.8137 - accuracy: 0.6746 - val_loss: 0.9508 - val_accuracy: 0.6113\n",
      "Epoch 123/450\n",
      "716/716 [==============================] - 1s 945us/sample - loss: 0.7810 - accuracy: 0.7039 - val_loss: 0.9580 - val_accuracy: 0.6194\n",
      "Epoch 124/450\n",
      "716/716 [==============================] - 1s 865us/sample - loss: 0.7906 - accuracy: 0.6872 - val_loss: 0.9496 - val_accuracy: 0.6235\n",
      "Epoch 125/450\n",
      "716/716 [==============================] - 1s 857us/sample - loss: 0.7976 - accuracy: 0.6746 - val_loss: 0.9482 - val_accuracy: 0.6113\n",
      "Epoch 126/450\n",
      "716/716 [==============================] - 1s 895us/sample - loss: 0.7700 - accuracy: 0.7053 - val_loss: 0.9482 - val_accuracy: 0.6154\n",
      "Epoch 127/450\n",
      "716/716 [==============================] - 1s 879us/sample - loss: 0.8071 - accuracy: 0.6620 - val_loss: 0.9460 - val_accuracy: 0.6073\n",
      "Epoch 128/450\n",
      "716/716 [==============================] - 0s 686us/sample - loss: 0.7868 - accuracy: 0.7039 - val_loss: 0.9472 - val_accuracy: 0.6275\n",
      "Epoch 129/450\n",
      "716/716 [==============================] - 0s 680us/sample - loss: 0.7717 - accuracy: 0.6802 - val_loss: 0.9584 - val_accuracy: 0.6113\n",
      "Epoch 130/450\n",
      "716/716 [==============================] - 0s 696us/sample - loss: 0.7499 - accuracy: 0.7025 - val_loss: 0.9537 - val_accuracy: 0.6113\n",
      "Epoch 131/450\n",
      "716/716 [==============================] - 0s 674us/sample - loss: 0.7716 - accuracy: 0.6983 - val_loss: 0.9522 - val_accuracy: 0.6275\n",
      "Epoch 132/450\n",
      "716/716 [==============================] - 1s 758us/sample - loss: 0.7616 - accuracy: 0.7011 - val_loss: 0.9482 - val_accuracy: 0.6194\n",
      "Epoch 133/450\n",
      "716/716 [==============================] - 1s 827us/sample - loss: 0.7352 - accuracy: 0.7193 - val_loss: 0.9577 - val_accuracy: 0.6113\n",
      "Epoch 134/450\n",
      "716/716 [==============================] - 0s 642us/sample - loss: 0.7645 - accuracy: 0.7081 - val_loss: 0.9543 - val_accuracy: 0.6154\n",
      "Epoch 135/450\n",
      "716/716 [==============================] - 0s 678us/sample - loss: 0.7250 - accuracy: 0.6997 - val_loss: 0.9509 - val_accuracy: 0.6032\n",
      "Epoch 136/450\n",
      "716/716 [==============================] - 0s 675us/sample - loss: 0.7439 - accuracy: 0.7235 - val_loss: 0.9461 - val_accuracy: 0.6356\n",
      "Epoch 137/450\n",
      "716/716 [==============================] - 0s 676us/sample - loss: 0.7455 - accuracy: 0.6913 - val_loss: 0.9413 - val_accuracy: 0.6113\n",
      "Epoch 138/450\n",
      "716/716 [==============================] - 0s 678us/sample - loss: 0.7206 - accuracy: 0.6997 - val_loss: 0.9561 - val_accuracy: 0.6073\n",
      "Epoch 139/450\n",
      "716/716 [==============================] - 1s 820us/sample - loss: 0.7035 - accuracy: 0.7249 - val_loss: 0.9565 - val_accuracy: 0.6194\n",
      "Epoch 140/450\n",
      "716/716 [==============================] - 1s 929us/sample - loss: 0.7459 - accuracy: 0.7193 - val_loss: 0.9622 - val_accuracy: 0.6235\n",
      "Epoch 141/450\n",
      "716/716 [==============================] - 1s 918us/sample - loss: 0.7261 - accuracy: 0.7151 - val_loss: 0.9529 - val_accuracy: 0.6275\n",
      "Epoch 142/450\n",
      "716/716 [==============================] - 1s 923us/sample - loss: 0.6788 - accuracy: 0.7221 - val_loss: 0.9501 - val_accuracy: 0.6275\n",
      "Epoch 143/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 0.6922 - accuracy: 0.7346 - val_loss: 0.9741 - val_accuracy: 0.6073\n",
      "Epoch 144/450\n",
      "716/716 [==============================] - 1s 716us/sample - loss: 0.6867 - accuracy: 0.7374 - val_loss: 0.9704 - val_accuracy: 0.6194\n",
      "Epoch 145/450\n",
      "716/716 [==============================] - 1s 771us/sample - loss: 0.7377 - accuracy: 0.7151 - val_loss: 0.9598 - val_accuracy: 0.6235\n",
      "Epoch 146/450\n",
      "716/716 [==============================] - 1s 747us/sample - loss: 0.6455 - accuracy: 0.7402 - val_loss: 0.9729 - val_accuracy: 0.6275\n",
      "Epoch 147/450\n",
      "716/716 [==============================] - 1s 788us/sample - loss: 0.6681 - accuracy: 0.7277 - val_loss: 0.9789 - val_accuracy: 0.6194\n",
      "Epoch 148/450\n",
      "716/716 [==============================] - 1s 728us/sample - loss: 0.6927 - accuracy: 0.7318 - val_loss: 0.9721 - val_accuracy: 0.6275\n",
      "Epoch 149/450\n",
      "716/716 [==============================] - 0s 641us/sample - loss: 0.6780 - accuracy: 0.7346 - val_loss: 0.9648 - val_accuracy: 0.6275\n",
      "Epoch 150/450\n",
      "716/716 [==============================] - 1s 768us/sample - loss: 0.6572 - accuracy: 0.7612 - val_loss: 0.9740 - val_accuracy: 0.6275\n",
      "Epoch 151/450\n",
      "716/716 [==============================] - 1s 827us/sample - loss: 0.6113 - accuracy: 0.7682 - val_loss: 0.9734 - val_accuracy: 0.6194\n",
      "Epoch 152/450\n",
      "716/716 [==============================] - 1s 837us/sample - loss: 0.6231 - accuracy: 0.7472 - val_loss: 0.9857 - val_accuracy: 0.6275\n",
      "Epoch 153/450\n",
      "716/716 [==============================] - 1s 865us/sample - loss: 0.6572 - accuracy: 0.7458 - val_loss: 0.9868 - val_accuracy: 0.6275\n",
      "Epoch 154/450\n",
      "716/716 [==============================] - 1s 988us/sample - loss: 0.6534 - accuracy: 0.7416 - val_loss: 0.9975 - val_accuracy: 0.6316\n",
      "Epoch 155/450\n",
      "716/716 [==============================] - 1s 967us/sample - loss: 0.6216 - accuracy: 0.7640 - val_loss: 0.9925 - val_accuracy: 0.6154\n",
      "Epoch 156/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.6452 - accuracy: 0.7458 - val_loss: 0.9824 - val_accuracy: 0.6235\n",
      "Epoch 157/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.6375 - accuracy: 0.7528 - val_loss: 0.9866 - val_accuracy: 0.6316\n",
      "Epoch 158/450\n",
      "716/716 [==============================] - 1s 978us/sample - loss: 0.6034 - accuracy: 0.7793 - val_loss: 0.9896 - val_accuracy: 0.6397\n",
      "Epoch 159/450\n",
      "716/716 [==============================] - 1s 818us/sample - loss: 0.6479 - accuracy: 0.7374 - val_loss: 0.9777 - val_accuracy: 0.6397\n",
      "Epoch 160/450\n",
      "716/716 [==============================] - 1s 788us/sample - loss: 0.6358 - accuracy: 0.7626 - val_loss: 0.9830 - val_accuracy: 0.6194\n",
      "Epoch 161/450\n",
      "716/716 [==============================] - 1s 784us/sample - loss: 0.5894 - accuracy: 0.7709 - val_loss: 0.9788 - val_accuracy: 0.6235\n",
      "Epoch 162/450\n",
      "716/716 [==============================] - 1s 740us/sample - loss: 0.6273 - accuracy: 0.7444 - val_loss: 0.9786 - val_accuracy: 0.6316\n",
      "Epoch 163/450\n",
      "716/716 [==============================] - 1s 753us/sample - loss: 0.5997 - accuracy: 0.7654 - val_loss: 0.9944 - val_accuracy: 0.6316\n",
      "Epoch 164/450\n",
      "716/716 [==============================] - 1s 848us/sample - loss: 0.5659 - accuracy: 0.7696 - val_loss: 1.0084 - val_accuracy: 0.6235\n",
      "Epoch 165/450\n",
      "716/716 [==============================] - 1s 743us/sample - loss: 0.5953 - accuracy: 0.7849 - val_loss: 1.0093 - val_accuracy: 0.6275\n",
      "Epoch 166/450\n",
      "716/716 [==============================] - 1s 868us/sample - loss: 0.5906 - accuracy: 0.7793 - val_loss: 1.0051 - val_accuracy: 0.6356\n",
      "Epoch 167/450\n",
      "716/716 [==============================] - 1s 794us/sample - loss: 0.6107 - accuracy: 0.7696 - val_loss: 1.0015 - val_accuracy: 0.6356\n",
      "Epoch 168/450\n",
      "716/716 [==============================] - 1s 803us/sample - loss: 0.5529 - accuracy: 0.7793 - val_loss: 1.0174 - val_accuracy: 0.6154\n",
      "Epoch 169/450\n",
      "716/716 [==============================] - 1s 804us/sample - loss: 0.5693 - accuracy: 0.7821 - val_loss: 1.0237 - val_accuracy: 0.6113\n",
      "Epoch 170/450\n",
      "716/716 [==============================] - 1s 778us/sample - loss: 0.5546 - accuracy: 0.7835 - val_loss: 1.0149 - val_accuracy: 0.6397\n",
      "Epoch 171/450\n",
      "716/716 [==============================] - 1s 815us/sample - loss: 0.5633 - accuracy: 0.7989 - val_loss: 1.0338 - val_accuracy: 0.6275\n",
      "Epoch 172/450\n",
      "716/716 [==============================] - 1s 767us/sample - loss: 0.5182 - accuracy: 0.8003 - val_loss: 1.0420 - val_accuracy: 0.6356\n",
      "Epoch 173/450\n",
      "716/716 [==============================] - 1s 745us/sample - loss: 0.5089 - accuracy: 0.8031 - val_loss: 1.0727 - val_accuracy: 0.6478\n",
      "Epoch 174/450\n",
      "716/716 [==============================] - 1s 761us/sample - loss: 0.5469 - accuracy: 0.7835 - val_loss: 1.0710 - val_accuracy: 0.6275\n",
      "Epoch 175/450\n",
      "716/716 [==============================] - 1s 769us/sample - loss: 0.5254 - accuracy: 0.7891 - val_loss: 1.0824 - val_accuracy: 0.6194\n",
      "Epoch 176/450\n",
      "716/716 [==============================] - 0s 673us/sample - loss: 0.5436 - accuracy: 0.7933 - val_loss: 1.0894 - val_accuracy: 0.6113\n",
      "Epoch 177/450\n",
      "716/716 [==============================] - 1s 797us/sample - loss: 0.5277 - accuracy: 0.7877 - val_loss: 1.0837 - val_accuracy: 0.6275\n",
      "Epoch 178/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.5328 - accuracy: 0.7989 - val_loss: 1.0619 - val_accuracy: 0.6478\n",
      "Epoch 179/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.5084 - accuracy: 0.7961 - val_loss: 1.0811 - val_accuracy: 0.6478\n",
      "Epoch 180/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.5113 - accuracy: 0.7975 - val_loss: 1.0967 - val_accuracy: 0.6275\n",
      "Epoch 181/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.5007 - accuracy: 0.7947 - val_loss: 1.0684 - val_accuracy: 0.6356\n",
      "Epoch 182/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.4886 - accuracy: 0.7877 - val_loss: 1.0595 - val_accuracy: 0.6397\n",
      "Epoch 183/450\n",
      "716/716 [==============================] - 1s 785us/sample - loss: 0.5071 - accuracy: 0.8017 - val_loss: 1.0771 - val_accuracy: 0.6316\n",
      "Epoch 184/450\n",
      "716/716 [==============================] - 1s 814us/sample - loss: 0.5328 - accuracy: 0.7933 - val_loss: 1.0439 - val_accuracy: 0.6437\n",
      "Epoch 185/450\n",
      "716/716 [==============================] - 0s 625us/sample - loss: 0.5113 - accuracy: 0.7835 - val_loss: 1.0353 - val_accuracy: 0.6478\n",
      "Epoch 186/450\n",
      "716/716 [==============================] - 0s 675us/sample - loss: 0.5334 - accuracy: 0.7933 - val_loss: 1.0570 - val_accuracy: 0.6559\n",
      "Epoch 187/450\n",
      "716/716 [==============================] - 1s 728us/sample - loss: 0.4820 - accuracy: 0.8226 - val_loss: 1.0641 - val_accuracy: 0.6478\n",
      "Epoch 188/450\n",
      "716/716 [==============================] - 1s 702us/sample - loss: 0.5114 - accuracy: 0.7933 - val_loss: 1.0567 - val_accuracy: 0.6316\n",
      "Epoch 189/450\n",
      "716/716 [==============================] - 0s 694us/sample - loss: 0.4929 - accuracy: 0.7919 - val_loss: 1.0560 - val_accuracy: 0.6437\n",
      "Epoch 190/450\n",
      "716/716 [==============================] - 1s 713us/sample - loss: 0.4739 - accuracy: 0.8115 - val_loss: 1.0728 - val_accuracy: 0.6437\n",
      "Epoch 191/450\n",
      "716/716 [==============================] - 0s 610us/sample - loss: 0.5137 - accuracy: 0.7779 - val_loss: 1.0726 - val_accuracy: 0.6356\n",
      "Epoch 192/450\n",
      "716/716 [==============================] - 0s 674us/sample - loss: 0.4977 - accuracy: 0.8310 - val_loss: 1.0714 - val_accuracy: 0.6397\n",
      "Epoch 193/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.4404 - accuracy: 0.8254 - val_loss: 1.0908 - val_accuracy: 0.6316\n",
      "Epoch 194/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.4368 - accuracy: 0.8436 - val_loss: 1.1074 - val_accuracy: 0.6275\n",
      "Epoch 195/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.4822 - accuracy: 0.8115 - val_loss: 1.0929 - val_accuracy: 0.6356\n",
      "Epoch 196/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.4671 - accuracy: 0.8240 - val_loss: 1.0836 - val_accuracy: 0.6437\n",
      "Epoch 197/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.4546 - accuracy: 0.8198 - val_loss: 1.0936 - val_accuracy: 0.6397\n",
      "Epoch 198/450\n",
      "716/716 [==============================] - 0s 669us/sample - loss: 0.4424 - accuracy: 0.8450 - val_loss: 1.1143 - val_accuracy: 0.6397\n",
      "Epoch 199/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.4582 - accuracy: 0.8436 - val_loss: 1.1235 - val_accuracy: 0.6397\n",
      "Epoch 200/450\n",
      "716/716 [==============================] - 0s 639us/sample - loss: 0.4484 - accuracy: 0.8310 - val_loss: 1.1544 - val_accuracy: 0.6316\n",
      "Epoch 201/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.4438 - accuracy: 0.8240 - val_loss: 1.1105 - val_accuracy: 0.6316\n",
      "Epoch 202/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.4559 - accuracy: 0.8268 - val_loss: 1.1112 - val_accuracy: 0.6397\n",
      "Epoch 203/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.4702 - accuracy: 0.8296 - val_loss: 1.1338 - val_accuracy: 0.6397\n",
      "Epoch 204/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.4391 - accuracy: 0.8394 - val_loss: 1.1125 - val_accuracy: 0.6356\n",
      "Epoch 205/450\n",
      "716/716 [==============================] - 0s 670us/sample - loss: 0.3917 - accuracy: 0.8561 - val_loss: 1.1265 - val_accuracy: 0.6397\n",
      "Epoch 206/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.4225 - accuracy: 0.8408 - val_loss: 1.1411 - val_accuracy: 0.6437\n",
      "Epoch 207/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.3874 - accuracy: 0.8603 - val_loss: 1.1531 - val_accuracy: 0.6397\n",
      "Epoch 208/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.4230 - accuracy: 0.8296 - val_loss: 1.1537 - val_accuracy: 0.6316\n",
      "Epoch 209/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.4763 - accuracy: 0.8212 - val_loss: 1.1377 - val_accuracy: 0.6356\n",
      "Epoch 210/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.4007 - accuracy: 0.8645 - val_loss: 1.1324 - val_accuracy: 0.6316\n",
      "Epoch 211/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.3859 - accuracy: 0.8561 - val_loss: 1.1504 - val_accuracy: 0.6437\n",
      "Epoch 212/450\n",
      "716/716 [==============================] - 0s 671us/sample - loss: 0.4072 - accuracy: 0.8450 - val_loss: 1.2026 - val_accuracy: 0.6356\n",
      "Epoch 213/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.4166 - accuracy: 0.8436 - val_loss: 1.1985 - val_accuracy: 0.6235\n",
      "Epoch 214/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.4105 - accuracy: 0.8506 - val_loss: 1.1917 - val_accuracy: 0.6316\n",
      "Epoch 215/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.3836 - accuracy: 0.8422 - val_loss: 1.2101 - val_accuracy: 0.6316\n",
      "Epoch 216/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.4154 - accuracy: 0.8352 - val_loss: 1.1825 - val_accuracy: 0.6356\n",
      "Epoch 217/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.3615 - accuracy: 0.8631 - val_loss: 1.1977 - val_accuracy: 0.6437\n",
      "Epoch 218/450\n",
      "716/716 [==============================] - 0s 660us/sample - loss: 0.3766 - accuracy: 0.8575 - val_loss: 1.2163 - val_accuracy: 0.6316\n",
      "Epoch 219/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.3817 - accuracy: 0.8492 - val_loss: 1.2413 - val_accuracy: 0.6397\n",
      "Epoch 220/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.3461 - accuracy: 0.8589 - val_loss: 1.2458 - val_accuracy: 0.6397\n",
      "Epoch 221/450\n",
      "716/716 [==============================] - 0s 646us/sample - loss: 0.3805 - accuracy: 0.8799 - val_loss: 1.2604 - val_accuracy: 0.6275\n",
      "Epoch 222/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.4027 - accuracy: 0.8631 - val_loss: 1.2285 - val_accuracy: 0.6316\n",
      "Epoch 223/450\n",
      "716/716 [==============================] - 0s 659us/sample - loss: 0.3692 - accuracy: 0.8645 - val_loss: 1.2211 - val_accuracy: 0.6235\n",
      "Epoch 224/450\n",
      "716/716 [==============================] - 0s 658us/sample - loss: 0.3402 - accuracy: 0.8617 - val_loss: 1.2434 - val_accuracy: 0.6356\n",
      "Epoch 225/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.3597 - accuracy: 0.8603 - val_loss: 1.2270 - val_accuracy: 0.6316\n",
      "Epoch 226/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.4033 - accuracy: 0.8575 - val_loss: 1.2272 - val_accuracy: 0.6397\n",
      "Epoch 227/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.3478 - accuracy: 0.8659 - val_loss: 1.2517 - val_accuracy: 0.6154\n",
      "Epoch 228/450\n",
      "716/716 [==============================] - 0s 659us/sample - loss: 0.3630 - accuracy: 0.8561 - val_loss: 1.2789 - val_accuracy: 0.6235\n",
      "Epoch 229/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.3643 - accuracy: 0.8617 - val_loss: 1.2686 - val_accuracy: 0.6194\n",
      "Epoch 230/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.3051 - accuracy: 0.8897 - val_loss: 1.2984 - val_accuracy: 0.6275\n",
      "Epoch 231/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.3804 - accuracy: 0.8645 - val_loss: 1.2884 - val_accuracy: 0.6154\n",
      "Epoch 232/450\n",
      "716/716 [==============================] - 0s 659us/sample - loss: 0.3546 - accuracy: 0.8715 - val_loss: 1.2985 - val_accuracy: 0.6154\n",
      "Epoch 233/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.3402 - accuracy: 0.8701 - val_loss: 1.3075 - val_accuracy: 0.6113\n",
      "Epoch 234/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.3011 - accuracy: 0.9050 - val_loss: 1.3440 - val_accuracy: 0.6154\n",
      "Epoch 235/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.3355 - accuracy: 0.8715 - val_loss: 1.3481 - val_accuracy: 0.6154\n",
      "Epoch 236/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.3363 - accuracy: 0.8673 - val_loss: 1.3568 - val_accuracy: 0.6275\n",
      "Epoch 237/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.3316 - accuracy: 0.8757 - val_loss: 1.3371 - val_accuracy: 0.6316\n",
      "Epoch 238/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.3345 - accuracy: 0.8743 - val_loss: 1.3426 - val_accuracy: 0.6316\n",
      "Epoch 239/450\n",
      "716/716 [==============================] - 0s 660us/sample - loss: 0.3183 - accuracy: 0.8813 - val_loss: 1.3260 - val_accuracy: 0.6235\n",
      "Epoch 240/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2990 - accuracy: 0.8911 - val_loss: 1.3492 - val_accuracy: 0.6356\n",
      "Epoch 241/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.3176 - accuracy: 0.8841 - val_loss: 1.3245 - val_accuracy: 0.6235\n",
      "Epoch 242/450\n",
      "716/716 [==============================] - 0s 660us/sample - loss: 0.3550 - accuracy: 0.8673 - val_loss: 1.3232 - val_accuracy: 0.6194\n",
      "Epoch 243/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.3076 - accuracy: 0.8813 - val_loss: 1.3441 - val_accuracy: 0.6235\n",
      "Epoch 244/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.3261 - accuracy: 0.8785 - val_loss: 1.3724 - val_accuracy: 0.6275\n",
      "Epoch 245/450\n",
      "716/716 [==============================] - 0s 659us/sample - loss: 0.2903 - accuracy: 0.8855 - val_loss: 1.4039 - val_accuracy: 0.6194\n",
      "Epoch 246/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.3061 - accuracy: 0.8827 - val_loss: 1.4032 - val_accuracy: 0.6275\n",
      "Epoch 247/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2670 - accuracy: 0.8897 - val_loss: 1.4158 - val_accuracy: 0.6356\n",
      "Epoch 248/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.3108 - accuracy: 0.8799 - val_loss: 1.3956 - val_accuracy: 0.6356\n",
      "Epoch 249/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.3274 - accuracy: 0.8911 - val_loss: 1.3822 - val_accuracy: 0.6275\n",
      "Epoch 250/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2973 - accuracy: 0.9008 - val_loss: 1.3901 - val_accuracy: 0.6356\n",
      "Epoch 251/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2862 - accuracy: 0.8883 - val_loss: 1.4065 - val_accuracy: 0.6275\n",
      "Epoch 252/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2996 - accuracy: 0.9036 - val_loss: 1.4045 - val_accuracy: 0.5992\n",
      "Epoch 253/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2939 - accuracy: 0.8883 - val_loss: 1.4262 - val_accuracy: 0.6316\n",
      "Epoch 254/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.2810 - accuracy: 0.8939 - val_loss: 1.4475 - val_accuracy: 0.6316\n",
      "Epoch 255/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.3221 - accuracy: 0.8799 - val_loss: 1.4340 - val_accuracy: 0.6316\n",
      "Epoch 256/450\n",
      "716/716 [==============================] - 0s 679us/sample - loss: 0.2704 - accuracy: 0.9036 - val_loss: 1.4815 - val_accuracy: 0.6154\n",
      "Epoch 257/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2710 - accuracy: 0.8785 - val_loss: 1.5135 - val_accuracy: 0.6275\n",
      "Epoch 258/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2638 - accuracy: 0.9064 - val_loss: 1.5107 - val_accuracy: 0.6316\n",
      "Epoch 259/450\n",
      "716/716 [==============================] - 0s 657us/sample - loss: 0.2902 - accuracy: 0.9008 - val_loss: 1.5339 - val_accuracy: 0.6235\n",
      "Epoch 260/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.3123 - accuracy: 0.8799 - val_loss: 1.4857 - val_accuracy: 0.6113\n",
      "Epoch 261/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2459 - accuracy: 0.8980 - val_loss: 1.4991 - val_accuracy: 0.6154\n",
      "Epoch 262/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2756 - accuracy: 0.8966 - val_loss: 1.4839 - val_accuracy: 0.6032\n",
      "Epoch 263/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2412 - accuracy: 0.9078 - val_loss: 1.4763 - val_accuracy: 0.5911\n",
      "Epoch 264/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2539 - accuracy: 0.9106 - val_loss: 1.4850 - val_accuracy: 0.6194\n",
      "Epoch 265/450\n",
      "716/716 [==============================] - 0s 674us/sample - loss: 0.2360 - accuracy: 0.9162 - val_loss: 1.5225 - val_accuracy: 0.6113\n",
      "Epoch 266/450\n",
      "716/716 [==============================] - 0s 660us/sample - loss: 0.2371 - accuracy: 0.9106 - val_loss: 1.5252 - val_accuracy: 0.6113\n",
      "Epoch 267/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2398 - accuracy: 0.9148 - val_loss: 1.5579 - val_accuracy: 0.6113\n",
      "Epoch 268/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.2501 - accuracy: 0.9036 - val_loss: 1.5674 - val_accuracy: 0.6235\n",
      "Epoch 269/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.3150 - accuracy: 0.8994 - val_loss: 1.4742 - val_accuracy: 0.6235\n",
      "Epoch 270/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.2638 - accuracy: 0.9064 - val_loss: 1.4983 - val_accuracy: 0.6113\n",
      "Epoch 271/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2478 - accuracy: 0.9176 - val_loss: 1.4991 - val_accuracy: 0.6194\n",
      "Epoch 272/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2204 - accuracy: 0.9218 - val_loss: 1.5132 - val_accuracy: 0.6235\n",
      "Epoch 273/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2362 - accuracy: 0.9078 - val_loss: 1.5353 - val_accuracy: 0.6113\n",
      "Epoch 274/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2666 - accuracy: 0.8980 - val_loss: 1.5345 - val_accuracy: 0.6235\n",
      "Epoch 275/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.2543 - accuracy: 0.9092 - val_loss: 1.5454 - val_accuracy: 0.6154\n",
      "Epoch 276/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2551 - accuracy: 0.9134 - val_loss: 1.5244 - val_accuracy: 0.6235\n",
      "Epoch 277/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2264 - accuracy: 0.9106 - val_loss: 1.5262 - val_accuracy: 0.6154\n",
      "Epoch 278/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.2086 - accuracy: 0.9302 - val_loss: 1.5229 - val_accuracy: 0.6235\n",
      "Epoch 279/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2395 - accuracy: 0.9106 - val_loss: 1.5288 - val_accuracy: 0.6235\n",
      "Epoch 280/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.2173 - accuracy: 0.9190 - val_loss: 1.5905 - val_accuracy: 0.6113\n",
      "Epoch 281/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2705 - accuracy: 0.9078 - val_loss: 1.5540 - val_accuracy: 0.6194\n",
      "Epoch 282/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.1993 - accuracy: 0.9176 - val_loss: 1.5628 - val_accuracy: 0.6194\n",
      "Epoch 283/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2161 - accuracy: 0.9288 - val_loss: 1.5705 - val_accuracy: 0.6073\n",
      "Epoch 284/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2238 - accuracy: 0.9106 - val_loss: 1.5932 - val_accuracy: 0.6154\n",
      "Epoch 285/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2134 - accuracy: 0.9176 - val_loss: 1.6345 - val_accuracy: 0.5992\n",
      "Epoch 286/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2406 - accuracy: 0.9246 - val_loss: 1.6108 - val_accuracy: 0.6235\n",
      "Epoch 287/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2388 - accuracy: 0.9190 - val_loss: 1.5771 - val_accuracy: 0.6316\n",
      "Epoch 288/450\n",
      "716/716 [==============================] - 0s 678us/sample - loss: 0.1821 - accuracy: 0.9399 - val_loss: 1.5989 - val_accuracy: 0.6073\n",
      "Epoch 289/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.2395 - accuracy: 0.9120 - val_loss: 1.5578 - val_accuracy: 0.6194\n",
      "Epoch 290/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2478 - accuracy: 0.9190 - val_loss: 1.5250 - val_accuracy: 0.6113\n",
      "Epoch 291/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.1804 - accuracy: 0.9358 - val_loss: 1.5713 - val_accuracy: 0.6235\n",
      "Epoch 292/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2002 - accuracy: 0.9413 - val_loss: 1.5926 - val_accuracy: 0.6154\n",
      "Epoch 293/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.2041 - accuracy: 0.9120 - val_loss: 1.6376 - val_accuracy: 0.6235\n",
      "Epoch 294/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2429 - accuracy: 0.9176 - val_loss: 1.6103 - val_accuracy: 0.6316\n",
      "Epoch 295/450\n",
      "716/716 [==============================] - 0s 659us/sample - loss: 0.2274 - accuracy: 0.9120 - val_loss: 1.6205 - val_accuracy: 0.6316\n",
      "Epoch 296/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.1852 - accuracy: 0.9344 - val_loss: 1.6446 - val_accuracy: 0.6397\n",
      "Epoch 297/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.2300 - accuracy: 0.9274 - val_loss: 1.5791 - val_accuracy: 0.6397\n",
      "Epoch 298/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.1758 - accuracy: 0.9385 - val_loss: 1.6196 - val_accuracy: 0.6316\n",
      "Epoch 299/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.2002 - accuracy: 0.9232 - val_loss: 1.6729 - val_accuracy: 0.6194\n",
      "Epoch 300/450\n",
      "716/716 [==============================] - 0s 658us/sample - loss: 0.2008 - accuracy: 0.9302 - val_loss: 1.6425 - val_accuracy: 0.6154\n",
      "Epoch 301/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.1616 - accuracy: 0.9455 - val_loss: 1.6956 - val_accuracy: 0.6275\n",
      "Epoch 302/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.2415 - accuracy: 0.9260 - val_loss: 1.6775 - val_accuracy: 0.6194\n",
      "Epoch 303/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.1858 - accuracy: 0.9316 - val_loss: 1.6589 - val_accuracy: 0.6113\n",
      "Epoch 304/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2412 - accuracy: 0.9120 - val_loss: 1.6315 - val_accuracy: 0.6194\n",
      "Epoch 305/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.2069 - accuracy: 0.9316 - val_loss: 1.6580 - val_accuracy: 0.6032\n",
      "Epoch 306/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.1503 - accuracy: 0.9483 - val_loss: 1.6755 - val_accuracy: 0.6073\n",
      "Epoch 307/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.2239 - accuracy: 0.9288 - val_loss: 1.6435 - val_accuracy: 0.6194\n",
      "Epoch 308/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.2075 - accuracy: 0.9190 - val_loss: 1.6009 - val_accuracy: 0.6113\n",
      "Epoch 309/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.1901 - accuracy: 0.9372 - val_loss: 1.6149 - val_accuracy: 0.6113\n",
      "Epoch 310/450\n",
      "716/716 [==============================] - 0s 661us/sample - loss: 0.1876 - accuracy: 0.9330 - val_loss: 1.6584 - val_accuracy: 0.6194\n",
      "Epoch 311/450\n",
      "716/716 [==============================] - 0s 666us/sample - loss: 0.1986 - accuracy: 0.9358 - val_loss: 1.6870 - val_accuracy: 0.6154\n",
      "Epoch 312/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.1953 - accuracy: 0.9218 - val_loss: 1.6945 - val_accuracy: 0.6073\n",
      "Epoch 313/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.1730 - accuracy: 0.9372 - val_loss: 1.6651 - val_accuracy: 0.6113\n",
      "Epoch 314/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.1406 - accuracy: 0.9497 - val_loss: 1.6999 - val_accuracy: 0.6235\n",
      "Epoch 315/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.1897 - accuracy: 0.9302 - val_loss: 1.7141 - val_accuracy: 0.6032\n",
      "Epoch 316/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.1214 - accuracy: 0.9595 - val_loss: 1.7473 - val_accuracy: 0.5992\n",
      "Epoch 317/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.1724 - accuracy: 0.9316 - val_loss: 1.7825 - val_accuracy: 0.6235\n",
      "Epoch 318/450\n",
      "716/716 [==============================] - 0s 664us/sample - loss: 0.1433 - accuracy: 0.9455 - val_loss: 1.7897 - val_accuracy: 0.6316\n",
      "Epoch 319/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.1664 - accuracy: 0.9385 - val_loss: 1.7685 - val_accuracy: 0.6275\n",
      "Epoch 320/450\n",
      "716/716 [==============================] - 0s 669us/sample - loss: 0.2112 - accuracy: 0.9246 - val_loss: 1.7337 - val_accuracy: 0.6235\n",
      "Epoch 321/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.1592 - accuracy: 0.9455 - val_loss: 1.7721 - val_accuracy: 0.6356\n",
      "Epoch 322/450\n",
      "716/716 [==============================] - 0s 668us/sample - loss: 0.1870 - accuracy: 0.9358 - val_loss: 1.7578 - val_accuracy: 0.6154\n",
      "Epoch 323/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.1926 - accuracy: 0.9344 - val_loss: 1.7648 - val_accuracy: 0.6275\n",
      "Epoch 324/450\n",
      "716/716 [==============================] - 0s 665us/sample - loss: 0.1681 - accuracy: 0.9427 - val_loss: 1.7881 - val_accuracy: 0.6235\n",
      "Epoch 325/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.2258 - accuracy: 0.9302 - val_loss: 1.7693 - val_accuracy: 0.6032\n",
      "Epoch 326/450\n",
      "716/716 [==============================] - 0s 662us/sample - loss: 0.1471 - accuracy: 0.9455 - val_loss: 1.7949 - val_accuracy: 0.5951\n",
      "Epoch 327/450\n",
      "716/716 [==============================] - 0s 683us/sample - loss: 0.1587 - accuracy: 0.9497 - val_loss: 1.8198 - val_accuracy: 0.5992\n",
      "Epoch 328/450\n",
      "716/716 [==============================] - 1s 743us/sample - loss: 0.1589 - accuracy: 0.9385 - val_loss: 1.8204 - val_accuracy: 0.6113\n",
      "Epoch 329/450\n",
      "716/716 [==============================] - 1s 804us/sample - loss: 0.1822 - accuracy: 0.9385 - val_loss: 1.8006 - val_accuracy: 0.6073\n",
      "Epoch 330/450\n",
      "716/716 [==============================] - 1s 754us/sample - loss: 0.1537 - accuracy: 0.9385 - val_loss: 1.8218 - val_accuracy: 0.5992\n",
      "Epoch 331/450\n",
      "716/716 [==============================] - 1s 760us/sample - loss: 0.1745 - accuracy: 0.9497 - val_loss: 1.7884 - val_accuracy: 0.6032\n",
      "Epoch 332/450\n",
      "716/716 [==============================] - 1s 770us/sample - loss: 0.1835 - accuracy: 0.9413 - val_loss: 1.8066 - val_accuracy: 0.6113\n",
      "Epoch 333/450\n",
      "716/716 [==============================] - 1s 749us/sample - loss: 0.1319 - accuracy: 0.9609 - val_loss: 1.8304 - val_accuracy: 0.5992\n",
      "Epoch 334/450\n",
      "716/716 [==============================] - 1s 753us/sample - loss: 0.1737 - accuracy: 0.9330 - val_loss: 1.8226 - val_accuracy: 0.5870\n",
      "Epoch 335/450\n",
      "716/716 [==============================] - 1s 753us/sample - loss: 0.1367 - accuracy: 0.9567 - val_loss: 1.8325 - val_accuracy: 0.6073\n",
      "Epoch 336/450\n",
      "716/716 [==============================] - 1s 792us/sample - loss: 0.1236 - accuracy: 0.9609 - val_loss: 1.9037 - val_accuracy: 0.5951\n",
      "Epoch 337/450\n",
      "716/716 [==============================] - 0s 632us/sample - loss: 0.1604 - accuracy: 0.9511 - val_loss: 1.9180 - val_accuracy: 0.5830\n",
      "Epoch 338/450\n",
      "716/716 [==============================] - 0s 697us/sample - loss: 0.1702 - accuracy: 0.9330 - val_loss: 1.8700 - val_accuracy: 0.6032\n",
      "Epoch 339/450\n",
      "716/716 [==============================] - 0s 685us/sample - loss: 0.1584 - accuracy: 0.9455 - val_loss: 1.8660 - val_accuracy: 0.6113\n",
      "Epoch 340/450\n",
      "716/716 [==============================] - 1s 818us/sample - loss: 0.1858 - accuracy: 0.9483 - val_loss: 1.8543 - val_accuracy: 0.5992\n",
      "Epoch 341/450\n",
      "716/716 [==============================] - 1s 780us/sample - loss: 0.1389 - accuracy: 0.9511 - val_loss: 1.8947 - val_accuracy: 0.5870\n",
      "Epoch 342/450\n",
      "716/716 [==============================] - 0s 654us/sample - loss: 0.1531 - accuracy: 0.9511 - val_loss: 1.8806 - val_accuracy: 0.5992\n",
      "Epoch 343/450\n",
      "716/716 [==============================] - 1s 862us/sample - loss: 0.1933 - accuracy: 0.9399 - val_loss: 1.8440 - val_accuracy: 0.5951\n",
      "Epoch 344/450\n",
      "716/716 [==============================] - 1s 820us/sample - loss: 0.1575 - accuracy: 0.9385 - val_loss: 1.8891 - val_accuracy: 0.5830\n",
      "Epoch 345/450\n",
      "716/716 [==============================] - 1s 806us/sample - loss: 0.1428 - accuracy: 0.9497 - val_loss: 1.8893 - val_accuracy: 0.6032\n",
      "Epoch 346/450\n",
      "716/716 [==============================] - 0s 651us/sample - loss: 0.1377 - accuracy: 0.9497 - val_loss: 1.9199 - val_accuracy: 0.5911\n",
      "Epoch 347/450\n",
      "716/716 [==============================] - 1s 727us/sample - loss: 0.1312 - accuracy: 0.9455 - val_loss: 1.9623 - val_accuracy: 0.5992\n",
      "Epoch 348/450\n",
      "716/716 [==============================] - 1s 746us/sample - loss: 0.1288 - accuracy: 0.9511 - val_loss: 1.9593 - val_accuracy: 0.5951\n",
      "Epoch 349/450\n",
      "716/716 [==============================] - 1s 754us/sample - loss: 0.1515 - accuracy: 0.9427 - val_loss: 1.9499 - val_accuracy: 0.5951\n",
      "Epoch 350/450\n",
      "716/716 [==============================] - 1s 741us/sample - loss: 0.1637 - accuracy: 0.9372 - val_loss: 1.9990 - val_accuracy: 0.6154\n",
      "Epoch 351/450\n",
      "716/716 [==============================] - 1s 793us/sample - loss: 0.1498 - accuracy: 0.9525 - val_loss: 1.9619 - val_accuracy: 0.6154\n",
      "Epoch 352/450\n",
      "716/716 [==============================] - 1s 862us/sample - loss: 0.1509 - accuracy: 0.9623 - val_loss: 1.9410 - val_accuracy: 0.6073\n",
      "Epoch 353/450\n",
      "716/716 [==============================] - 1s 807us/sample - loss: 0.1600 - accuracy: 0.9399 - val_loss: 1.9275 - val_accuracy: 0.6113\n",
      "Epoch 354/450\n",
      "716/716 [==============================] - 1s 766us/sample - loss: 0.1483 - accuracy: 0.9497 - val_loss: 1.8754 - val_accuracy: 0.5911\n",
      "Epoch 355/450\n",
      "716/716 [==============================] - 1s 906us/sample - loss: 0.1556 - accuracy: 0.9469 - val_loss: 1.9298 - val_accuracy: 0.5951\n",
      "Epoch 356/450\n",
      "716/716 [==============================] - 1s 857us/sample - loss: 0.1139 - accuracy: 0.9567 - val_loss: 1.9306 - val_accuracy: 0.5992\n",
      "Epoch 357/450\n",
      "716/716 [==============================] - 1s 910us/sample - loss: 0.1087 - accuracy: 0.9651 - val_loss: 1.9841 - val_accuracy: 0.6032\n",
      "Epoch 358/450\n",
      "716/716 [==============================] - 1s 987us/sample - loss: 0.1273 - accuracy: 0.9567 - val_loss: 2.0141 - val_accuracy: 0.5992\n",
      "Epoch 359/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.1710 - accuracy: 0.9358 - val_loss: 2.0087 - val_accuracy: 0.5951\n",
      "Epoch 360/450\n",
      "716/716 [==============================] - 1s 1ms/sample - loss: 0.0979 - accuracy: 0.9665 - val_loss: 2.0239 - val_accuracy: 0.5992\n",
      "Epoch 361/450\n",
      "716/716 [==============================] - 1s 884us/sample - loss: 0.1276 - accuracy: 0.9623 - val_loss: 2.0195 - val_accuracy: 0.6032\n",
      "Epoch 362/450\n",
      "716/716 [==============================] - 1s 868us/sample - loss: 0.1744 - accuracy: 0.9469 - val_loss: 2.0006 - val_accuracy: 0.6073\n",
      "Epoch 363/450\n",
      "716/716 [==============================] - 1s 940us/sample - loss: 0.1124 - accuracy: 0.9623 - val_loss: 1.9828 - val_accuracy: 0.6113\n",
      "Epoch 364/450\n",
      "716/716 [==============================] - 1s 878us/sample - loss: 0.1030 - accuracy: 0.9595 - val_loss: 2.0170 - val_accuracy: 0.6113\n",
      "Epoch 365/450\n",
      "716/716 [==============================] - 1s 716us/sample - loss: 0.0899 - accuracy: 0.9665 - val_loss: 2.0832 - val_accuracy: 0.6113\n",
      "Epoch 366/450\n",
      "716/716 [==============================] - 1s 772us/sample - loss: 0.1502 - accuracy: 0.9399 - val_loss: 2.0808 - val_accuracy: 0.6235\n",
      "Epoch 367/450\n",
      "716/716 [==============================] - 1s 801us/sample - loss: 0.1626 - accuracy: 0.9497 - val_loss: 2.0475 - val_accuracy: 0.6154\n",
      "Epoch 368/450\n",
      "716/716 [==============================] - 1s 756us/sample - loss: 0.1240 - accuracy: 0.9539 - val_loss: 2.0856 - val_accuracy: 0.5992\n",
      "Epoch 369/450\n",
      "716/716 [==============================] - 1s 771us/sample - loss: 0.1314 - accuracy: 0.9525 - val_loss: 2.0928 - val_accuracy: 0.6032\n",
      "Epoch 370/450\n",
      "716/716 [==============================] - 1s 802us/sample - loss: 0.1537 - accuracy: 0.9497 - val_loss: 2.0113 - val_accuracy: 0.6073\n",
      "Epoch 371/450\n",
      "716/716 [==============================] - 1s 788us/sample - loss: 0.1375 - accuracy: 0.9609 - val_loss: 1.9604 - val_accuracy: 0.5951\n",
      "Epoch 372/450\n",
      "716/716 [==============================] - 1s 770us/sample - loss: 0.1535 - accuracy: 0.9539 - val_loss: 1.9273 - val_accuracy: 0.6073\n",
      "Epoch 373/450\n",
      "716/716 [==============================] - 1s 759us/sample - loss: 0.1452 - accuracy: 0.9441 - val_loss: 1.9290 - val_accuracy: 0.6154\n",
      "Epoch 374/450\n",
      "716/716 [==============================] - 1s 742us/sample - loss: 0.1314 - accuracy: 0.9539 - val_loss: 1.9184 - val_accuracy: 0.6073\n",
      "Epoch 375/450\n",
      "716/716 [==============================] - 1s 930us/sample - loss: 0.1207 - accuracy: 0.9595 - val_loss: 1.9841 - val_accuracy: 0.6437\n",
      "Epoch 376/450\n",
      "716/716 [==============================] - 1s 845us/sample - loss: 0.1370 - accuracy: 0.9609 - val_loss: 2.0340 - val_accuracy: 0.6073\n",
      "Epoch 377/450\n",
      "716/716 [==============================] - 1s 775us/sample - loss: 0.1354 - accuracy: 0.9511 - val_loss: 2.0403 - val_accuracy: 0.6032\n",
      "Epoch 378/450\n",
      "716/716 [==============================] - 1s 802us/sample - loss: 0.1136 - accuracy: 0.9609 - val_loss: 2.0461 - val_accuracy: 0.6194\n",
      "Epoch 379/450\n",
      "716/716 [==============================] - 0s 693us/sample - loss: 0.0995 - accuracy: 0.9707 - val_loss: 2.0980 - val_accuracy: 0.6194\n",
      "Epoch 380/450\n",
      "716/716 [==============================] - 1s 715us/sample - loss: 0.1502 - accuracy: 0.9497 - val_loss: 2.0577 - val_accuracy: 0.6235\n",
      "Epoch 381/450\n",
      "716/716 [==============================] - 1s 735us/sample - loss: 0.0930 - accuracy: 0.9707 - val_loss: 2.0789 - val_accuracy: 0.6113\n",
      "Epoch 382/450\n",
      "716/716 [==============================] - 1s 829us/sample - loss: 0.1363 - accuracy: 0.9511 - val_loss: 2.0417 - val_accuracy: 0.6235\n",
      "Epoch 383/450\n",
      "716/716 [==============================] - 0s 673us/sample - loss: 0.1417 - accuracy: 0.9539 - val_loss: 1.9893 - val_accuracy: 0.6073\n",
      "Epoch 384/450\n",
      "716/716 [==============================] - 0s 678us/sample - loss: 0.1420 - accuracy: 0.9413 - val_loss: 1.9985 - val_accuracy: 0.6073\n",
      "Epoch 385/450\n",
      "716/716 [==============================] - 0s 686us/sample - loss: 0.0959 - accuracy: 0.9721 - val_loss: 1.9841 - val_accuracy: 0.6032\n",
      "Epoch 386/450\n",
      "716/716 [==============================] - 1s 733us/sample - loss: 0.1198 - accuracy: 0.9623 - val_loss: 2.0183 - val_accuracy: 0.6073\n",
      "Epoch 387/450\n",
      "716/716 [==============================] - 1s 815us/sample - loss: 0.1255 - accuracy: 0.9581 - val_loss: 2.0125 - val_accuracy: 0.6154\n",
      "Epoch 388/450\n",
      "716/716 [==============================] - 1s 894us/sample - loss: 0.0918 - accuracy: 0.9651 - val_loss: 2.0426 - val_accuracy: 0.6073\n",
      "Epoch 389/450\n",
      "716/716 [==============================] - 1s 833us/sample - loss: 0.1132 - accuracy: 0.9595 - val_loss: 2.0811 - val_accuracy: 0.6032\n",
      "Epoch 390/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.1135 - accuracy: 0.9623 - val_loss: 2.0995 - val_accuracy: 0.5911\n",
      "Epoch 391/450\n",
      "716/716 [==============================] - 0s 663us/sample - loss: 0.1267 - accuracy: 0.9483 - val_loss: 2.0828 - val_accuracy: 0.6073\n",
      "Epoch 392/450\n",
      "716/716 [==============================] - 0s 673us/sample - loss: 0.1674 - accuracy: 0.9399 - val_loss: 2.0529 - val_accuracy: 0.6073\n",
      "Epoch 393/450\n",
      "716/716 [==============================] - 1s 747us/sample - loss: 0.1240 - accuracy: 0.9595 - val_loss: 1.9717 - val_accuracy: 0.5951\n",
      "Epoch 394/450\n",
      "716/716 [==============================] - 1s 720us/sample - loss: 0.0809 - accuracy: 0.9693 - val_loss: 2.0115 - val_accuracy: 0.5992\n",
      "Epoch 395/450\n",
      "716/716 [==============================] - 1s 720us/sample - loss: 0.1096 - accuracy: 0.9637 - val_loss: 2.0603 - val_accuracy: 0.6032\n",
      "Epoch 396/450\n",
      "716/716 [==============================] - 1s 798us/sample - loss: 0.0823 - accuracy: 0.9721 - val_loss: 2.1342 - val_accuracy: 0.6032\n",
      "Epoch 397/450\n",
      "716/716 [==============================] - 1s 729us/sample - loss: 0.1135 - accuracy: 0.9567 - val_loss: 2.1147 - val_accuracy: 0.5992\n",
      "Epoch 398/450\n",
      "716/716 [==============================] - 1s 736us/sample - loss: 0.0965 - accuracy: 0.9679 - val_loss: 2.1930 - val_accuracy: 0.6032\n",
      "Epoch 399/450\n",
      "716/716 [==============================] - 1s 725us/sample - loss: 0.1293 - accuracy: 0.9665 - val_loss: 2.1148 - val_accuracy: 0.5951\n",
      "Epoch 400/450\n",
      "716/716 [==============================] - 1s 735us/sample - loss: 0.0752 - accuracy: 0.9693 - val_loss: 2.1893 - val_accuracy: 0.5911\n",
      "Epoch 401/450\n",
      "716/716 [==============================] - 1s 800us/sample - loss: 0.1328 - accuracy: 0.9511 - val_loss: 2.1185 - val_accuracy: 0.5951\n",
      "Epoch 402/450\n",
      "716/716 [==============================] - 1s 762us/sample - loss: 0.1582 - accuracy: 0.9469 - val_loss: 2.0386 - val_accuracy: 0.5870\n",
      "Epoch 403/450\n",
      "716/716 [==============================] - 1s 751us/sample - loss: 0.0827 - accuracy: 0.9693 - val_loss: 2.1064 - val_accuracy: 0.5911\n",
      "Epoch 404/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 0.1293 - accuracy: 0.9539 - val_loss: 2.0641 - val_accuracy: 0.5911\n",
      "Epoch 405/450\n",
      "716/716 [==============================] - 1s 880us/sample - loss: 0.1044 - accuracy: 0.9609 - val_loss: 2.0498 - val_accuracy: 0.5951\n",
      "Epoch 406/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.1258 - accuracy: 0.9553 - val_loss: 2.0709 - val_accuracy: 0.6235\n",
      "Epoch 407/450\n",
      "716/716 [==============================] - 1s 782us/sample - loss: 0.0866 - accuracy: 0.9707 - val_loss: 2.0977 - val_accuracy: 0.6113\n",
      "Epoch 408/450\n",
      "716/716 [==============================] - 1s 948us/sample - loss: 0.1103 - accuracy: 0.9525 - val_loss: 2.0546 - val_accuracy: 0.6073\n",
      "Epoch 409/450\n",
      "716/716 [==============================] - 1s 825us/sample - loss: 0.1115 - accuracy: 0.9609 - val_loss: 2.0737 - val_accuracy: 0.6113\n",
      "Epoch 410/450\n",
      "716/716 [==============================] - 1s 724us/sample - loss: 0.1190 - accuracy: 0.9651 - val_loss: 2.0520 - val_accuracy: 0.6113\n",
      "Epoch 411/450\n",
      "716/716 [==============================] - 1s 764us/sample - loss: 0.1076 - accuracy: 0.9623 - val_loss: 2.0275 - val_accuracy: 0.6073\n",
      "Epoch 412/450\n",
      "716/716 [==============================] - 1s 791us/sample - loss: 0.0838 - accuracy: 0.9707 - val_loss: 2.0784 - val_accuracy: 0.6032\n",
      "Epoch 413/450\n",
      "716/716 [==============================] - 1s 841us/sample - loss: 0.0804 - accuracy: 0.9693 - val_loss: 2.1214 - val_accuracy: 0.5992\n",
      "Epoch 414/450\n",
      "716/716 [==============================] - 0s 681us/sample - loss: 0.1056 - accuracy: 0.9623 - val_loss: 2.1649 - val_accuracy: 0.5870\n",
      "Epoch 415/450\n",
      "716/716 [==============================] - 1s 776us/sample - loss: 0.1250 - accuracy: 0.9595 - val_loss: 2.1521 - val_accuracy: 0.5992\n",
      "Epoch 416/450\n",
      "716/716 [==============================] - 1s 790us/sample - loss: 0.0972 - accuracy: 0.9651 - val_loss: 2.0906 - val_accuracy: 0.5992\n",
      "Epoch 417/450\n",
      "716/716 [==============================] - 1s 775us/sample - loss: 0.0941 - accuracy: 0.9735 - val_loss: 2.1445 - val_accuracy: 0.6073\n",
      "Epoch 418/450\n",
      "716/716 [==============================] - 1s 792us/sample - loss: 0.1121 - accuracy: 0.9637 - val_loss: 2.1491 - val_accuracy: 0.5830\n",
      "Epoch 419/450\n",
      "716/716 [==============================] - 1s 771us/sample - loss: 0.1355 - accuracy: 0.9567 - val_loss: 2.1345 - val_accuracy: 0.5992\n",
      "Epoch 420/450\n",
      "716/716 [==============================] - 0s 697us/sample - loss: 0.1139 - accuracy: 0.9581 - val_loss: 2.1367 - val_accuracy: 0.6032\n",
      "Epoch 421/450\n",
      "716/716 [==============================] - 1s 808us/sample - loss: 0.0957 - accuracy: 0.9623 - val_loss: 2.1854 - val_accuracy: 0.6032\n",
      "Epoch 422/450\n",
      "716/716 [==============================] - 1s 780us/sample - loss: 0.0908 - accuracy: 0.9693 - val_loss: 2.2903 - val_accuracy: 0.6032\n",
      "Epoch 423/450\n",
      "716/716 [==============================] - 1s 711us/sample - loss: 0.0678 - accuracy: 0.9791 - val_loss: 2.3543 - val_accuracy: 0.5992\n",
      "Epoch 424/450\n",
      "716/716 [==============================] - 1s 758us/sample - loss: 0.1113 - accuracy: 0.9595 - val_loss: 2.3432 - val_accuracy: 0.5992\n",
      "Epoch 425/450\n",
      "716/716 [==============================] - 1s 731us/sample - loss: 0.0883 - accuracy: 0.9679 - val_loss: 2.3590 - val_accuracy: 0.6073\n",
      "Epoch 426/450\n",
      "716/716 [==============================] - 0s 696us/sample - loss: 0.0764 - accuracy: 0.9763 - val_loss: 2.4021 - val_accuracy: 0.5951\n",
      "Epoch 427/450\n",
      "716/716 [==============================] - 1s 808us/sample - loss: 0.1199 - accuracy: 0.9623 - val_loss: 2.3856 - val_accuracy: 0.5870\n",
      "Epoch 428/450\n",
      "716/716 [==============================] - 1s 773us/sample - loss: 0.0895 - accuracy: 0.9707 - val_loss: 2.3787 - val_accuracy: 0.5911\n",
      "Epoch 429/450\n",
      "716/716 [==============================] - 1s 794us/sample - loss: 0.1129 - accuracy: 0.9623 - val_loss: 2.3472 - val_accuracy: 0.5992\n",
      "Epoch 430/450\n",
      "716/716 [==============================] - 1s 738us/sample - loss: 0.1208 - accuracy: 0.9567 - val_loss: 2.3148 - val_accuracy: 0.5992\n",
      "Epoch 431/450\n",
      "716/716 [==============================] - 1s 830us/sample - loss: 0.0909 - accuracy: 0.9693 - val_loss: 2.3613 - val_accuracy: 0.5870\n",
      "Epoch 432/450\n",
      "716/716 [==============================] - 1s 817us/sample - loss: 0.1069 - accuracy: 0.9637 - val_loss: 2.3075 - val_accuracy: 0.6032\n",
      "Epoch 433/450\n",
      "716/716 [==============================] - 1s 748us/sample - loss: 0.0815 - accuracy: 0.9721 - val_loss: 2.2761 - val_accuracy: 0.5992\n",
      "Epoch 434/450\n",
      "716/716 [==============================] - 1s 744us/sample - loss: 0.0701 - accuracy: 0.9804 - val_loss: 2.3228 - val_accuracy: 0.6073\n",
      "Epoch 435/450\n",
      "716/716 [==============================] - 1s 746us/sample - loss: 0.1104 - accuracy: 0.9651 - val_loss: 2.3448 - val_accuracy: 0.5951\n",
      "Epoch 436/450\n",
      "716/716 [==============================] - 1s 759us/sample - loss: 0.0828 - accuracy: 0.9707 - val_loss: 2.3459 - val_accuracy: 0.5951\n",
      "Epoch 437/450\n",
      "716/716 [==============================] - 0s 667us/sample - loss: 0.0667 - accuracy: 0.9804 - val_loss: 2.3808 - val_accuracy: 0.5951\n",
      "Epoch 438/450\n",
      "716/716 [==============================] - 1s 746us/sample - loss: 0.1012 - accuracy: 0.9665 - val_loss: 2.3538 - val_accuracy: 0.6073\n",
      "Epoch 439/450\n",
      "716/716 [==============================] - 1s 829us/sample - loss: 0.1020 - accuracy: 0.9665 - val_loss: 2.3768 - val_accuracy: 0.5870\n",
      "Epoch 440/450\n",
      "716/716 [==============================] - 1s 919us/sample - loss: 0.0958 - accuracy: 0.9693 - val_loss: 2.3423 - val_accuracy: 0.5992\n",
      "Epoch 441/450\n",
      "716/716 [==============================] - 1s 887us/sample - loss: 0.0964 - accuracy: 0.9637 - val_loss: 2.3313 - val_accuracy: 0.6032\n",
      "Epoch 442/450\n",
      "716/716 [==============================] - 1s 835us/sample - loss: 0.1000 - accuracy: 0.9651 - val_loss: 2.3152 - val_accuracy: 0.5992\n",
      "Epoch 443/450\n",
      "716/716 [==============================] - 1s 863us/sample - loss: 0.0904 - accuracy: 0.9679 - val_loss: 2.3043 - val_accuracy: 0.5951\n",
      "Epoch 444/450\n",
      "716/716 [==============================] - 1s 912us/sample - loss: 0.1275 - accuracy: 0.9525 - val_loss: 2.2131 - val_accuracy: 0.5951\n",
      "Epoch 445/450\n",
      "716/716 [==============================] - 1s 872us/sample - loss: 0.1088 - accuracy: 0.9553 - val_loss: 2.2406 - val_accuracy: 0.5870\n",
      "Epoch 446/450\n",
      "716/716 [==============================] - 1s 723us/sample - loss: 0.0782 - accuracy: 0.9735 - val_loss: 2.2050 - val_accuracy: 0.6073\n",
      "Epoch 447/450\n",
      "716/716 [==============================] - 1s 765us/sample - loss: 0.0927 - accuracy: 0.9665 - val_loss: 2.2422 - val_accuracy: 0.6032\n",
      "Epoch 448/450\n",
      "716/716 [==============================] - 1s 869us/sample - loss: 0.0903 - accuracy: 0.9707 - val_loss: 2.2794 - val_accuracy: 0.6113\n",
      "Epoch 449/450\n",
      "716/716 [==============================] - 1s 793us/sample - loss: 0.1005 - accuracy: 0.9693 - val_loss: 2.2293 - val_accuracy: 0.6032\n",
      "Epoch 450/450\n",
      "716/716 [==============================] - 1s 773us/sample - loss: 0.0747 - accuracy: 0.9791 - val_loss: 2.2585 - val_accuracy: 0.6073\n"
     ]
    }
   ],
   "source": [
    "H=model.fit(emb,labels,validation_data=(embT,labelsT),epochs=450,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\SRKT\\Desktop\\opencv-face-recognition\\output\\Test\\recognizer2.h5\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pickle.loads(open(r\"C:\\Users\\SRKT\\Desktop\\opencv-face-recognition\\output\\Test\\embeddings.pickle\",\"rb\").read())\n",
    "le=LabelEncoder()\n",
    "labels=le.fit_transform(data[\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec=SVC(C=1.0,kernel=\"linear\",probability=True)\n",
    "rec.fit(data[\"embedding\"],labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r\"C:\\Users\\SRKT\\Desktop\\opencv-face-recognition\\output\\Test\\svm.pickle\",\"wb\")\n",
    "f.write(pickle.dumps(rec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
